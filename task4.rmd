## Problem 3.
#### The expected value of the poisson distribution E (λ) is λ, so that a good point estimate of the parameter θ := λ is the sample mean x. Confidence interval for θ can be formed in several different ways

```{r}
library(crayon)
```

```{r}
id <- 1

n <- 1000
m <- 500
alphas <- c(0.1, 0.05, 0.01)
theta <- id / 10
lambda <- theta
datas <- matrix(rpois(n * m, lambda = lambda), nrow = n)


alphas <- c(0.1, 0.05, 0.01)
```

### A. Verify that the confidence intervals of level 1 − a constructed via (1)–(4) above contain the parameter θ = λ approx. 100(1 − α)% of times.

#### (1) Approximating using chi-square distribution.

The $(1-\alpha)100$ confidence interval for $\lambda$ is:
$$\left[\frac{\chi^2(2n\overline{x},\ \alpha/2)}{2n},\ \frac{\chi^2(2n\overline{x},\ 1-\alpha/2)}{2n}\right]$$
$\chi^2(v,\ p)$ is the p'th quantile of chi-square distribution with v degrees of freedom.

```{r}
rate_chi <- c(0, 0, 0)
lengths_chi <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        left <- qchisq(alphas[k] / 2, df = 2 * n * mean) / (2 * n)
        right <- qchisq(1 - alphas[k] / 2, df = 2 * n * mean) / (2 * n)

        lengths_chi <- append(lengths_chi, right - left)
        if (left <= lambda & lambda <= right) {
            rate_chi[k] <- rate_chi[k] + 1
        }
    }
}
rate_chi <- rate_chi / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_chi[k], "\n")
}
```

#### (2) Approximating using normal approximation with known variance.
$$ \mu=\theta\ \ \ \ \sigma^2 = \theta $$
$$ X\sim\mathcal{N}(\theta,\ \theta)$$

The $(1-\alpha)$ confidence level for $\lambda$ then is:
$$\left[\overline{X} - \sigma Z_{1-\alpha/2},\overline{X} + \sigma Z_{1-\alpha/2}\right]$$

```{r}
sd <- sqrt(theta)

rate_known_var <- c(0, 0, 0)
lengths_known_var <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        z <- qnorm(1 - alphas[k] / 2, mean = 0, sd = 1)
        epsilon <- sd * z
        left <- mean - epsilon
        right <- mean + epsilon

        lengths_known_var <- append(lengths_known_var, right - left)
        if (left <= theta & theta <= right) {
            rate_known_var[k] <- rate_known_var[k] + 1
        }
    }
}
rate_known_var <- rate_known_var / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_known_var[k], "\n")
}
```

#### (3) Approximating using normal approximation with unknown variance.
Basically doing same steps as in (2), but now we are calculating standart deviation from our data. 

```{r}
rate_unknown_var <- c(0, 0, 0)
lengths_unknown_var <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        sd <- sd(datas[, i])
        z <- qnorm(1 - alphas[k] / 2, mean = 0, sd = 1)
        epsilon <- sd * z

        left <- mean - epsilon
        right <- mean + epsilon
        lengths_unknown_var <- append(lengths_unknown_var, right - left)
        if (left <= theta & theta <= right) {
            rate_unknown_var[k] <- rate_unknown_var[k] + 1
        }
    }
}
rate_unknown_var <- rate_unknown_var / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_unknown_var[k], "\n")
}
```

### B. Compare their precision (lengths).
```{r}
cat("The avarage length using chi-square distribution:", mean(lengths_chi))
cat("The avarage length using normal approximation with known variance:", mean(lengths_known_var))
cat("The avarage length using normal approximation with unknown variance:", mean(lengths_unknown_var))
```

### C. Compare their precision (lengths).
In Poisson distribution case, the best option is chi-squared distribution extimation, as it gives small interval, therefore giving us a very valuable information.
Other two gave us very high precision, but big intervals, so they are not optimal to use in Poisson distribution case.
