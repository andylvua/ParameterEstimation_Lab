## Problem 3.
#### The expected value of the exponential distribution E (λ) is 1/λ, so that a good point estimate of the parameter θ := 1/λ is the sample mean x. Confidence interval for θ can be formed in several different ways

```{r}
library(crayon)
```

```{r}
id <- 1

n <- 1000
m <- 500
alphas <- c(0.1, 0.05, 0.01)
theta <- id / 10
lambda <- 1 / theta
datas <- matrix(rexp(n * m, rate = lambda), nrow = n)


alphas <- c(0.1, 0.05, 0.01)
```

### A. Verify that the confidence intervals of level 1 − a constructed via (1)–(4) above contain the parameter θ = 1/λ approx. 100(1 − α)% of times.

#### (1) Approximating using chi-square distribution.

$$\mathcal{E}(\lambda) \sim \mathcal{G}(1,\ 1/{\lambda})$$
$$\sum^{iid}\mathcal{G}(1,\ 1/{\lambda}) \sim \mathcal{G}(n,\ 1/{\lambda})\sim 0.5\chi^2_{2n}$$

The $(1-\alpha)100$ confidence interval for $\lambda$ then is:
$$\left[\frac{\chi^2(2n,\ \alpha/2)}{2n\overline{x}},\ \frac{\chi^2(2n,\ 1-\alpha/2)}{2n\overline{x}}\right]$$
$\chi^2(v,\ p)$ is the p'th quantile of chi-square distribution with v degrees of dreedom

```{r}
rate_chi <- c(0, 0, 0)
lengths_chi <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        left <- qchisq(alphas[k] / 2, df = 2 * n) / (2 * mean * n)
        right <- qchisq(1 - alphas[k] / 2, df = 2 * n) / (2 * mean * n)

        lengths_chi <- append(lengths_chi, right - left)
        if (left <= lambda & lambda <= right) {
            rate_chi[k] <- rate_chi[k] + 1
        }
    }
}
rate_chi <- rate_chi / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_chi[k], "\n")
}
```

#### (2) Approximating using normal approximation with known variance.
$$ \mu=\theta\ \ \ \ \sigma^2 = \theta^2 $$
$$ X\sim\mathcal{N}(\theta,\ \theta^2)$$

The $(1-\alpha)$ confidence level for $\lambda$ then is:
$$\left[\overline{X} - \frac{\sigma}{\sqrt{n}}Z_{1-\alpha/2},\overline{X} + \frac{\sigma}{\sqrt{n}}Z_{1-\alpha/2}\right]$$

```{r}
sd <- theta

rate_known_var <- c(0, 0, 0)
lengths_known_var <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        z <- qnorm(1 - alphas[k] / 2, mean = 0, sd = 1)
        epsilon <- sd / sqrt(n) * z
        left <- mean - epsilon
        right <- mean + epsilon

        lengths_known_var <- append(lengths_known_var, right - left)
        if (left <= theta & theta <= right) {
            rate_known_var[k] <- rate_known_var[k] + 1
        }
    }
}
rate_known_var <- rate_known_var / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_known_var[k], "\n")
}
```

#### (3) Approximating using normal approximation with unknown variance.
Basically doing same steps as in (2), but now we are calculating standart deviation from our data. 

```{r}
rate_unknown_var <- c(0, 0, 0)
lengths_unknown_var <- c()
for (k in 1:3) {
    for (i in 1:m) {
        mean <- mean(datas[, i])
        sd <- sd(datas[, i])
        z <- qnorm(1 - alphas[k] / 2, mean = 0, sd = 1)
        epsilon <- sd / sqrt(n) * z

        left <- mean - epsilon
        right <- mean + epsilon
        lengths_unknown_var <- append(lengths_unknown_var, right - left)
        if (left <= theta & theta <= right) {
            rate_unknown_var[k] <- rate_unknown_var[k] + 1
        }
    }
}
rate_unknown_var <- rate_unknown_var / m
for (k in 1:3) {
    cat("The approximation of parameter lambda when alpha =", alphas[k], "is:", rate_unknown_var[k], "\n")
}
```

### B. Compare their precision (lengths).
```{r}
cat("The avarage length using chi-square distribution:", mean(lengths_chi))
cat("The avarage length using normal approximation with known variance:", mean(lengths_known_var))
cat("The avarage length using normal approximation with unknown variance:", mean(lengths_unknown_var))
```

### C. Compare their precision (lengths).
The best method is obviously the normal approximation with unknown variance, as it can be widely used because of no need to have the population's variance.
Chi approximation is worse, because it returns a very wide interval for theta, when normal approximation is very precise.
